{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90d5f7a24a79b5b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set GPU Settings\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "#TURN OFF WHEN ACTUALLY TESTING CODE\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:22:45.765884200Z",
     "start_time": "2023-11-15T16:22:36.640344300Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6be1d18d03f78ee"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define CarDataSet Class\n",
    "class CarDataSet():\n",
    "\n",
    "    # Define The Initialization\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_transform=None):\n",
    "        self.cars = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.resize = transforms.Resize((150,150))  # Resize images to a uniform size\n",
    "\n",
    "    # Define The Length Function\n",
    "    def __len__(self):\n",
    "        return len(self.cars)\n",
    "\n",
    "    # Define The Get Item Function\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Pull The Image And Check Settings\n",
    "        img_name = os.path.join(self.root_dir, self.cars.iloc[idx, 0])\n",
    "\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "          image = image.convert('RGB')\n",
    "\n",
    "        # Pull The Label, -1 To Normalize To 0\n",
    "        label = (self.cars.iloc[idx, 5]) - 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Define The Dictionary\n",
    "        sample = {'image': image, 'cars': label}\n",
    "\n",
    "        # Return\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:22:45.780897200Z",
     "start_time": "2023-11-15T16:22:45.769387100Z"
    }
   },
   "id": "759e0bf9fe9a388b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define Transform\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "    \n",
    "# Load The Data\n",
    "train_data = CarDataSet(csv_file='../SynchronizationProject/stanford_cars_eec174/train_make.csv',\n",
    "                                        root_dir='../SynchronizationProject/stanford_cars_eec174/images/train', transform=transform)\n",
    "test_data = CarDataSet(csv_file='../SynchronizationProject/stanford_cars_eec174/val_make.csv',\n",
    "                                        root_dir='../SynchronizationProject/stanford_cars_eec174/images/val', transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:22:45.811923500Z",
     "start_time": "2023-11-15T16:22:45.783399Z"
    }
   },
   "id": "c9f8990b2487605"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def show_imgs(dataloader):\n",
    "    # Load Names From The File\n",
    "    with open('../SynchronizationProject/stanford_cars_eec174/names_make.txt', 'r') as file:\n",
    "        names = file.read().splitlines()\n",
    "\n",
    "    # Retrieve The Images And Labels\n",
    "    dataiter = iter(dataloader)\n",
    "    samples = next(dataiter)\n",
    "\n",
    "    images_show_img, labels_show_img = samples['image'], samples['cars']\n",
    "\n",
    "    # Grab Ten Random Indices\n",
    "    shuffled_indices = np.random.permutation(len(images_show_img))\n",
    "    indices = shuffled_indices[:10]\n",
    "\n",
    "    # Create Subplots\n",
    "    figure, axes = plt.subplots(1, 10, figsize=(20, 10))\n",
    "\n",
    "    for i, ax in zip(indices, axes):\n",
    "\n",
    "        # Rearrange Dimensions For Display\n",
    "        cur_image = images_show_img[i].permute(1, 2, 0)\n",
    "\n",
    "        # Convert The Label To An Integer\n",
    "        label_index = int(labels_show_img[i].item())\n",
    "\n",
    "        # Assign The Name Corresponding To The Label Index\n",
    "        cur_label = names[label_index]\n",
    "\n",
    "        # Display The Image\n",
    "        ax.imshow(cur_image)\n",
    "\n",
    "        # Display The Label As Title\n",
    "        ax.set_title(cur_label)\n",
    "\n",
    "        # Turn Off The Axis\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Test Accuracy\n",
    "def test_accuracy(model, test_loader_internal, passed_device, loss_fn):\n",
    "\n",
    "    # Set Parameters\n",
    "    model.to(passed_device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    run = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    # Run Tests\n",
    "    with torch.no_grad():\n",
    "        for test_data_internal in test_loader_internal:\n",
    "            images_test_acc, labels_test_acc = test_data_internal['image'].cuda(), test_data_internal['cars'].cuda()\n",
    "            outputs_test_acc = model(images_test_acc)\n",
    "            _, predicted_test_acc = torch.max(outputs_test_acc.data, 1)\n",
    "            val_loss += (loss_fn(outputs_test_acc, labels_test_acc)).item()\n",
    "            total += labels_test_acc.size(0)\n",
    "            correct += (predicted_test_acc == labels_test_acc).sum().item()\n",
    "            run += 1\n",
    "\n",
    "    # Return\n",
    "    return (100 * correct / total), val_loss/run\n",
    "\n",
    "\n",
    "# Plotting Function\n",
    "def general_plot(data_dict1: dict, data_dict2: dict, param: str, label1: str, label2: str, ylabel: str, reduce_noise: bool):\n",
    "    param_list1 = data_dict1[param]\n",
    "    param_list2 = data_dict2[param]\n",
    "\n",
    "    if reduce_noise:\n",
    "        param_list1.pop(0)\n",
    "        param_list2.pop(0)\n",
    "\n",
    "    # Prepare Plot\n",
    "    xs = [x for x in range(min(len(param_list1), len(param_list2)))]\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(xs, param_list1[:len(xs)], label=label1)\n",
    "    plt.plot(xs, param_list2[:len(xs)], label=label2)\n",
    "    plt.xlabel('Iterations (in batches)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f'Training and Validation {ylabel} Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Plot Learning Curves\n",
    "def plot_learning_curve(train_history_plt_curve: dict, val_history_plt_curve: dict, reduce_noise=True):\n",
    "\n",
    "    # Plot The Info\n",
    "    general_plot(train_history_plt_curve, val_history_plt_curve, 'loss', 'Training Loss', 'Validation Loss', 'Loss', reduce_noise)\n",
    "    general_plot(train_history_plt_curve, val_history_plt_curve, 'accuracy', 'Training Accuracy', 'Validation Accuracy', 'Accuracy', reduce_noise)\n",
    "    \n",
    "# Define and use confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names_confusion):\n",
    "\n",
    "    # Prepare Plot And Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix Frozen')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names_confusion))\n",
    "    plt.xticks(tick_marks, class_names_confusion, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names_confusion)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    # Show Everything\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Define Train\n",
    "def train(model, loss_fn, optimizer_train, train_loader_train, val_loader, num_epochs_train, device_train):\n",
    "\n",
    "    # Set Parameters\n",
    "    model.train()\n",
    "    BLUE = '\\033[94m'\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "    train_history_train = {'loss': [], 'accuracy': []}\n",
    "    val_history_train = {'loss': [], 'accuracy': []}\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Iterate Through All Epochs\n",
    "    for epoch in range(num_epochs_train):\n",
    "\n",
    "        # For Loop Parameters\n",
    "        start_time = time.time()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        # Iterate Through The Training Dataset\n",
    "        for i, data_train in enumerate(train_loader_train, 0):\n",
    "            \n",
    "            # Flatten Images And Load Data\n",
    "            images_train, labels_train = data_train['image'].cuda(), data_train['cars'].cuda()\n",
    "\n",
    "            # Zero Collected Gradients At Each Step (basically cleaning)\n",
    "            optimizer_train.zero_grad()\n",
    "\n",
    "            # Forward Propagate\n",
    "            outputs_train = model(images_train)\n",
    "\n",
    "            # Calculate Loss\n",
    "            loss = loss_fn(outputs_train, labels_train)\n",
    "\n",
    "            # Back Propagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update Weigh Gradsts\n",
    "            optimizer_train.step()\n",
    "\n",
    "            # Calculate Accuracy\n",
    "            _, predicted_train = torch.max(outputs_train.data, 1)\n",
    "            total += labels_train.size(0)\n",
    "            correct += (predicted_train == labels_train).sum().item()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += 100 * correct / total\n",
    "            train_total += 1\n",
    "            \n",
    "        # Evaluate Model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            val_acc, val_loss = test_accuracy(model, val_loader, device_train, loss_fn)\n",
    "\n",
    "            val_history_train['loss'].append(val_loss)\n",
    "            val_history_train['accuracy'].append(val_acc)\n",
    "\n",
    "            train_history_train['loss'].append(train_loss / train_total)\n",
    "            train_history_train['accuracy'].append(train_correct / train_total)\n",
    "\n",
    "            train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        # At End Of Each Epoch Print Duration And Accuracy\n",
    "        print(f'{BLUE}Epoch [{epoch+1}/{num_epochs_train}]:'f' Duration: {round(time.time() - start_time, 2)}s |'f' Train Acc: {round(train_history_train[\"accuracy\"][-1], 2)} |'f' Train Loss: {round(train_history_train[\"loss\"][-1], 5)}'f' Val Acc: {round(val_history_train[\"accuracy\"][-1], 2)} |'f' Val Loss: {round(val_history_train[\"loss\"][-1], 5)}{RESET}')\n",
    "        print('------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "        # Save Checkpoint\n",
    "        #PATH = '/content/drive/My Drive/WEIGHTSAVES/run' + str('78.8save') + 'epoch' + str(epoch+1) + 'ta' + str(train_history_train[\"accuracy\"][-1])[0:6] + 'tl' + str(train_history_train[\"loss\"][-1])[0:6] + 'va' + str(val_history_train[\"accuracy\"][-1])[0:6] + 'vl' + str(val_history_train[\"loss\"][-1])[0:6] + '.pth'\n",
    "        #print(PATH)\n",
    "        #torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    # Print Final Statistics\n",
    "    #print(f'{BLUE}Total Duration:{round(time.time() - total_start_time, 2)}s |',f'Final Train Acc: {round(train_history_train[\"accuracy\"][-1], 2)} |',f'Final Train Loss: {round(train_history_train[\"loss\"][-1], 5)} |',f'Final Val Acc: {round(val_history_train[\"accuracy\"][-1], 2)} |',f'Final Val Loss: {round(val_history_train[\"loss\"][-1], 5)}{RESET}')\n",
    "\n",
    "    # Return\n",
    "    return train_history_train, val_history_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:22:45.854960500Z",
     "start_time": "2023-11-15T16:22:45.827436700Z"
    }
   },
   "id": "c1fa020743f3bc96"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.cpu().numpy()\n",
    " \n",
    "def maximum_weight_aggregation(models_states):\n",
    "    aggregated_weights = {}\n",
    "    for param_name in models_states[0]:\n",
    "        all_weights = [to_numpy(model_state[param_name]) for model_state in models_states]\n",
    "        aggregated_weights[param_name] = torch.tensor(np.max(all_weights, axis=0))\n",
    "    return aggregated_weights, \"MaximumWeight\"\n",
    "\n",
    "def minimum_weight_aggregation(models_states):\n",
    "    aggregated_weights = {}\n",
    "    for param_name in models_states[0]:\n",
    "        all_weights = [to_numpy(model_state[param_name]) for model_state in models_states]\n",
    "        aggregated_weights[param_name] = torch.tensor(np.min(all_weights, axis=0))\n",
    "    return aggregated_weights, \"MinimumWeight\"\n",
    "\n",
    "def mean_aggregation(models_states):\n",
    "    aggregated_weights = {}\n",
    "    for param_name in models_states[0]:\n",
    "        all_weights = [to_numpy(model_state[param_name]) for model_state in models_states]\n",
    "        aggregated_weights[param_name] = torch.tensor(np.mean(all_weights, axis=0))\n",
    "    return aggregated_weights, \"MeanWeight\"\n",
    "\n",
    "def median_aggregation(models_states):\n",
    "    aggregated_weights = {}\n",
    "    for param_name in models_states[0]:\n",
    "        all_weights = [to_numpy(model_state[param_name]) for model_state in models_states]\n",
    "        aggregated_weights[param_name] = torch.tensor(np.median(all_weights, axis=0))\n",
    "    return aggregated_weights, \"MedianWeight\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T16:22:45.862467100Z",
     "start_time": "2023-11-15T16:22:45.847954500Z"
    }
   },
   "id": "ad4b7d75db541b7b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unchanging Definitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2fc42535bf12767"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#No Pretrained\n",
    "    \"0\": [1, 1, 1, False, 1], #Run 0: batch size 32, learning rate 0.0001, 1 GPU, 50 epochs\n",
    "    \"1\": [1, 1, 3, False, 1], #Run 1: batch size 32, learning rate 0.0001, 3 GPUs, 50 Epochs\n",
    "    \"2\": [1, 1, 6, False, 1], #Run 2: batch size 32, learning rate 0.0001, 6 GPU, 50 Epochs\n",
    "    \"3\": [1, 1, 10, False, 1], #Run 3: batch size 32, learning rate 0.0001, 10 GPUs, 50 Epochs\n",
    "    \n",
    "    \"4\": [1, 10, 1, False, 1], #Run 4: batch size 32, learning rate 0.001, 1 GPU, 50 epochs\n",
    "    \"5\": [1, 10, 3, False, 1], #Run 5: batch size 32, learning rate 0.001, 3 GPUs, 50 Epochs\n",
    "    \"6\": [1, 10, 6, False, 1], #Run 6: batch size 32, learning rate 0.001, 6 GPU, 50 Epochs\n",
    "    \"7\": [1, 10, 10, False, 1], #Run 7: batch size 32, learning rate 0.001, 10 GPUs, 50 Epochs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"8\": [2, 1, 1, False, 1], #Run 8: batch size 64, learning rate 0.0001, 1 GPU, 50 epochs\n",
    "    \"9\": [2, 1, 3, False, 1], #Run 9: batch size 64, learning rate 0.0001, 3 GPUs, 50 Epochs\n",
    "    \"10\": [2, 1, 6, False, 1], #Run 10: batch size 64, learning rate 0.0001, 6 GPU, 50 Epochs\n",
    "    \"11\": [2, 1, 10, False, 1], #Run 11: batch size 64, learning rate 0.0001, 10 GPUs, 50 Epochs\n",
    "    \n",
    "    \"12\": [2, 10, 1, False, 1], #Run 12: batch size 64, learning rate 0.001, 1 GPU, 50 epochs\n",
    "    \"13\": [2, 10, 3, False, 1], #Run 13: batch size 64, learning rate 0.001, 3 GPUs, 50 Epochs\n",
    "    \"14\": [2, 10, 6, False, 1], #Run 14: batch size 64, learning rate 0.001, 6 GPU, 50 Epochs\n",
    "    \"15\": [2, 10, 10, False, 1], #Run 15: batch size 64, learning rate 0.001, 10 GPUs, 50 Epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"16\": [1, 1, 1, False, 2], #Run 16: batch size 32, learning rate 0.0001, 1 GPU, 100 epochs\n",
    "\"17\": [1, 1, 3, False, 2], #Run 17: batch size 32, learning rate 0.0001, 3 GPUs, 100 Epochs\n",
    "\"18\": [1, 1, 6, False, 2], #Run 18: batch size 32, learning rate 0.0001, 6 GPU, 100 Epochs\n",
    "\"19\": [1, 1, 10, False, 2], #Run 19: batch size 32, learning rate 0.0001, 10 GPUs, 100 Epochs\n",
    "\"20\": [1, 10, 1, False, 2], #Run 20: batch size 32, learning rate 0.001, 1 GPU, 100 epochs\n",
    "\"21\": [1, 10, 3, False, 2], #Run 21: batch size 32, learning rate 0.001, 3 GPUs, 100 Epochs\n",
    "\"22\": [1, 10, 6, False, 2], #Run 22: batch size 32, learning rate 0.001, 6 GPU, 100 Epochs\n",
    "\"23\": [1, 10, 10, False, 2], #Run 23: batch size 32, learning rate 0.001, 10 GPUs, 100 Epochs\n",
    "\"24\": [2, 1, 1, False, 2], #Run 24: batch size 64, learning rate 0.0001, 1 GPU, 100 epochs\n",
    "\"25\": [2, 1, 3, False, 2], #Run 25: batch size 64, learning rate 0.0001, 3 GPUs, 100 Epochs\n",
    "\"26\": [2, 1, 6, False, 2], #Run 26: batch size 64, learning rate 0.0001, 6 GPU, 100 Epochs\n",
    "\"27\": [2, 1, 10, False, 2], #Run 27: batch size 64, learning rate 0.0001, 10 GPUs, 100 Epochs\n",
    "\"28\": [2, 10, 1, False, 2], #Run 28: batch size 64, learning rate 0.001, 1 GPU, 100 epochs\n",
    "\"29\": [2, 10, 3, False, 2], #Run 29: batch size 64, learning rate 0.001, 3 GPUs, 100 Epochs\n",
    "\"30\": [2, 10, 6, False, 2], #Run 30: batch size 64, learning rate 0.001, 6 GPU, 100 Epochs\n",
    "\"31\": [2, 10, 10, False, 2] #Run 31: batch size 64, learning rate 0.001, 10 GPUs, 100 Epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b970a5230750d972"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#[GPUcount num, pretrained (True=yes, False=no)] , savepath, sync amount\n",
    "\n",
    "operations_dictionary = {\n",
    "    \"0\":[1, True, 'PreSave15', 0],\n",
    "    \n",
    "    \"1\":[3, True, 'PreSave15', 1],\n",
    "    \"2\":[3, True, 'PreSave15', 3],\n",
    "    \"3\":[3, True, 'PreSave15', 5],\n",
    "    \"4\":[3, True, 'PreSave15', 10],\n",
    "\n",
    "    \"5\":[5, True, 'PreSave15', 1],\n",
    "    \"6\":[5, True, 'PreSave15', 3],\n",
    "    \"7\":[5, True, 'PreSave15', 5],\n",
    "    \"8\":[5, True, 'PreSave15', 10],\n",
    "\n",
    "    \"9\":[8, True, 'PreSave15', 1],\n",
    "    \"10\":[8, True, 'PreSave15', 3],\n",
    "    \"11\":[8, True, 'PreSave15', 5],\n",
    "    \"12\":[8, True, 'PreSave15', 10]\n",
    "    \n",
    "                         }\n",
    "# Dataset Size\n",
    "DATASET_SIZE = 8192\n",
    "\n",
    "# Define Parameters\n",
    "input_size = (768 * 1024)\n",
    "num_classes = 49\n",
    "\n",
    "InfoSave = pd.read_csv('../SynchronizationProject/SaveData/DataFrames/InfoSave.csv')#pd.DataFrame(columns = [\"Run\", \"BatchSize\", \"LearningRate\", \"Epochs\", \"TrainAccuracy\", \"TrainLoss\", \"TrainHistory\", \"ValAccuracy\", \"ValLoss\", \"ValHistory\", \"GPUCount\", \"PreTrain\", \"SyncAmount\", \"MergeType\", \"TrainTime\", \"SavePathInput\", \"SavePathOutput\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:09:39.489640900Z",
     "start_time": "2023-11-19T03:09:39.377545600Z"
    }
   },
   "id": "35a43b541b55111f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# net = models.resnet50()\n",
    "# net.fc = nn.Linear(net.fc.in_features, 49)\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# net.to(device)\n",
    "# \n",
    "# batch_size = 32\n",
    "# \n",
    "# # Import To Dataloaders\n",
    "# train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
    "# \n",
    "# # Specify Factors\n",
    "# lr = 0.0001\n",
    "# \n",
    "# # Loss Function and Optimizer\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# \n",
    "# # Run Train\n",
    "# train_history, val_history = train(net, loss_function, optimizer, train_loader, test_loader, 10, device)\n",
    "# \n",
    "# PATH = '../SynchronizationProject/SaveData/PreSave15.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T03:09:41.296521400Z",
     "start_time": "2023-11-19T03:09:41.266496400Z"
    }
   },
   "id": "436b9f69919512ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Setup and Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28c4faa3661b0397"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\u001B[94mEpoch [1/30]: Duration: 118.89s | Train Acc: 38.43 | Train Loss: 2.20695 Val Acc: 18.13 | Val Loss: 3.43426\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [2/30]: Duration: 107.66s | Train Acc: 49.21 | Train Loss: 1.81315 Val Acc: 19.78 | Val Loss: 3.31079\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [3/30]: Duration: 108.09s | Train Acc: 63.76 | Train Loss: 1.37811 Val Acc: 15.39 | Val Loss: 4.05527\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [4/30]: Duration: 108.31s | Train Acc: 75.84 | Train Loss: 0.9448 Val Acc: 17.96 | Val Loss: 3.99764\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [5/30]: Duration: 108.05s | Train Acc: 85.76 | Train Loss: 0.56562 Val Acc: 15.47 | Val Loss: 4.73438\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [6/30]: Duration: 109.37s | Train Acc: 91.48 | Train Loss: 0.35536 Val Acc: 15.6 | Val Loss: 4.9541\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [7/30]: Duration: 107.82s | Train Acc: 95.32 | Train Loss: 0.22632 Val Acc: 15.93 | Val Loss: 4.86574\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [8/30]: Duration: 107.78s | Train Acc: 97.47 | Train Loss: 0.14431 Val Acc: 16.09 | Val Loss: 4.75301\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [9/30]: Duration: 107.31s | Train Acc: 98.02 | Train Loss: 0.10996 Val Acc: 16.84 | Val Loss: 4.82941\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [10/30]: Duration: 107.33s | Train Acc: 97.21 | Train Loss: 0.18266 Val Acc: 12.94 | Val Loss: 6.22266\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [11/30]: Duration: 108.32s | Train Acc: 90.3 | Train Loss: 0.41412 Val Acc: 14.1 | Val Loss: 5.93887\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [12/30]: Duration: 107.57s | Train Acc: 89.52 | Train Loss: 0.32223 Val Acc: 15.51 | Val Loss: 5.40047\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [13/30]: Duration: 107.47s | Train Acc: 95.09 | Train Loss: 0.1505 Val Acc: 17.83 | Val Loss: 4.72294\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [14/30]: Duration: 107.3s | Train Acc: 98.42 | Train Loss: 0.06707 Val Acc: 19.83 | Val Loss: 4.63947\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [15/30]: Duration: 107.35s | Train Acc: 99.43 | Train Loss: 0.03308 Val Acc: 19.91 | Val Loss: 4.74969\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [16/30]: Duration: 107.76s | Train Acc: 99.59 | Train Loss: 0.02748 Val Acc: 19.29 | Val Loss: 4.61716\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [17/30]: Duration: 108.34s | Train Acc: 99.33 | Train Loss: 0.05358 Val Acc: 16.18 | Val Loss: 5.4797\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [18/30]: Duration: 108.22s | Train Acc: 94.28 | Train Loss: 0.29989 Val Acc: 13.52 | Val Loss: 5.91332\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [19/30]: Duration: 109.22s | Train Acc: 87.55 | Train Loss: 0.40073 Val Acc: 15.97 | Val Loss: 6.10373\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [20/30]: Duration: 108.08s | Train Acc: 94.84 | Train Loss: 0.16664 Val Acc: 18.58 | Val Loss: 5.34983\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [21/30]: Duration: 108.05s | Train Acc: 98.22 | Train Loss: 0.06098 Val Acc: 19.29 | Val Loss: 5.34354\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [22/30]: Duration: 107.57s | Train Acc: 99.59 | Train Loss: 0.02505 Val Acc: 20.16 | Val Loss: 5.04853\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [23/30]: Duration: 106.9s | Train Acc: 99.86 | Train Loss: 0.01248 Val Acc: 20.9 | Val Loss: 4.78932\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [24/30]: Duration: 106.8s | Train Acc: 99.92 | Train Loss: 0.00771 Val Acc: 20.86 | Val Loss: 4.89186\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [25/30]: Duration: 107.11s | Train Acc: 99.98 | Train Loss: 0.00532 Val Acc: 19.66 | Val Loss: 5.09719\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [26/30]: Duration: 106.87s | Train Acc: 100.0 | Train Loss: 0.00295 Val Acc: 21.15 | Val Loss: 4.87302\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [27/30]: Duration: 106.98s | Train Acc: 100.0 | Train Loss: 0.00196 Val Acc: 21.28 | Val Loss: 4.91565\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [28/30]: Duration: 106.69s | Train Acc: 100.0 | Train Loss: 0.00162 Val Acc: 21.15 | Val Loss: 4.8296\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [29/30]: Duration: 112.1s | Train Acc: 100.0 | Train Loss: 0.00149 Val Acc: 22.15 | Val Loss: 4.83594\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\u001B[94mEpoch [30/30]: Duration: 106.82s | Train Acc: 100.0 | Train Loss: 0.00127 Val Acc: 20.99 | Val Loss: 4.96344\u001B[0m\n",
      "------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Each Set of Models \n",
    "for run_number_key in operations_dictionary:\n",
    "    print(run_number_key)\n",
    "    \n",
    "    # Specify Factors\n",
    "    lr = 0.0001\n",
    "    batch_size = 32\n",
    "    num_epochs = 30 \n",
    "    \n",
    "    # Import To Dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
    "        \n",
    "    # Single GPU\n",
    "    if (operations_dictionary[run_number_key])[0] == 1:\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Model Definition and Final Layer Edit\n",
    "        net = models.resnet50()\n",
    "        net.fc = nn.Linear(net.fc.in_features, 49)\n",
    "\n",
    "        saved_model_path = \"\"\n",
    "\n",
    "        if (operations_dictionary[run_number_key])[1]:\n",
    "            # IF NEEDED TO IMPORT\n",
    "            saved_model_path = '../SynchronizationProject/SaveData/' + str((operations_dictionary[run_number_key])[2]) + '.pth'\n",
    "            net.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "        # Load Model Onto GPU\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        net.to(device)\n",
    "\n",
    "        # Loss Function and Optimizer\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "        # Run Train\n",
    "        train_history, val_history = train(net, loss_function, optimizer, train_loader, test_loader, num_epochs, device)\n",
    "\n",
    "        # Save Model\n",
    "        PATH = '../SynchronizationProject/SaveData/Weights/' + str(run_number_key) + '.pth'\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        trainacc, trainloss = test_accuracy(net, train_loader, device, loss_function)\n",
    "        valacc, valloss = test_accuracy(net, test_loader, device, loss_function)\n",
    "\n",
    "        new_row_data = {\n",
    "                \"Run\": run_number_key,\n",
    "                \"BatchSize\": batch_size,\n",
    "                \"LearningRate\": lr,\n",
    "                \"Epochs\": num_epochs,\n",
    "                \"TrainAccuracy\": trainacc,\n",
    "                \"TrainLoss\": trainloss,\n",
    "                \"ValAccuracy\": valacc,\n",
    "                \"ValLoss\": valloss,\n",
    "                \"GPUCount\": 1,\n",
    "                \"PreTrain\": (operations_dictionary[run_number_key])[1],\n",
    "                \"MergeType\": \"NONE\",\n",
    "                \"SyncAmount\": 1,\n",
    "                \"TrainTime\": total_time,\n",
    "                \"SavePathInput\": saved_model_path,\n",
    "                \"SavePathOutput\": PATH\n",
    "        }\n",
    "\n",
    "        # Adding the new row to the DataFrame\n",
    "        InfoSave.loc[len(InfoSave)] = new_row_data\n",
    "\n",
    "    # Multiple GPU\n",
    "    else:\n",
    "        #amount of gpus to run\n",
    "        amount_of_GPUs_to_run = (operations_dictionary[run_number_key])[0]\n",
    "\n",
    "        #make an array of input data to access\n",
    "        inputDataTrain = []\n",
    "        for datasetNum in range(amount_of_GPUs_to_run):\n",
    "            start_idx = (len(train_loader.dataset) // amount_of_GPUs_to_run) * datasetNum\n",
    "\n",
    "            if datasetNum < (amount_of_GPUs_to_run - 1):\n",
    "                end_idx = (len(train_loader.dataset) // amount_of_GPUs_to_run) * (datasetNum + 1)\n",
    "            else:\n",
    "                end_idx = len(train_loader.dataset)\n",
    "\n",
    "            split_data_set = torch.utils.data.Subset(train_loader.dataset, range(start_idx, end_idx))\n",
    "            split_train_loader = torch.utils.data.DataLoader(dataset=split_data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            inputDataTrain.append(split_train_loader)\n",
    "\n",
    "        #iterate through each type of synchronizatyion, there are 4\n",
    "        for syncType in range(4):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Model Definition and Final Layer Edit\n",
    "            net = models.resnet50()\n",
    "            net.fc = nn.Linear(net.fc.in_features, 49)\n",
    "\n",
    "            saved_model_path = \"\"\n",
    "\n",
    "            if (operations_dictionary[run_number_key])[1]:\n",
    "                # IF NEEDED TO IMPORT\n",
    "                saved_model_path = '../SynchronizationProject/SaveData/' + str((operations_dictionary[run_number_key])[2]) + '.pth'\n",
    "                net.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "            # Loss Function and Optimizer\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "            #iterate through all the syncs\n",
    "            for syncNum in range((operations_dictionary[run_number_key])[3]):\n",
    "                print(\"SyncNum: \" + str(syncNum))\n",
    "                weightsList = []\n",
    "                #iterate through all the GPU trains\n",
    "                for gpuNumRun in range(amount_of_GPUs_to_run):\n",
    "                    print(\"gpuNumRun: \" + str(gpuNumRun))\n",
    "                    # Load Model Onto GPU\n",
    "                    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "                    net.to(device)\n",
    "\n",
    "                    #train\n",
    "                    train_history, val_history = train(net, loss_function, optimizer, inputDataTrain[gpuNumRun], test_loader, num_epochs//(operations_dictionary[run_number_key])[3], device)\n",
    "                    \n",
    "                    weightsList.append(net.state_dict())\n",
    "\n",
    "                    #sync them\n",
    "                if syncType == 0:\n",
    "                    weightOutput, name = maximum_weight_aggregation(weightsList)\n",
    "                elif syncType == 1:\n",
    "                    weightOutput, name = minimum_weight_aggregation(weightsList)\n",
    "                elif syncType == 2:\n",
    "                    weightOutput, name = median_aggregation(weightsList)\n",
    "                elif syncType == 3:\n",
    "                    weightOutput, name = mean_aggregation(weightsList)\n",
    "\n",
    "                net.load_state_dict(weightOutput)\n",
    "                \n",
    "\n",
    "            #save final sync output and move onto next sync\n",
    "\n",
    "            # Save Model\n",
    "            PATH = '../SynchronizationProject/SaveData/Weights/' + str(run_number_key) + str(name) + '.pth'\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "            \n",
    "            print(\"That was \" + name)\n",
    "\n",
    "            total_time = time.time() - start_time\n",
    "\n",
    "            trainacc, trainloss = test_accuracy(net, train_loader, device, loss_function)\n",
    "            valacc, valloss = test_accuracy(net, test_loader, device, loss_function)\n",
    "\n",
    "            new_row_data = {\n",
    "                        \"Run\": run_number_key,\n",
    "                        \"BatchSize\": batch_size,\n",
    "                        \"LearningRate\": lr,\n",
    "                        \"Epochs\": num_epochs,\n",
    "                        \"TrainAccuracy\": trainacc,\n",
    "                        \"TrainLoss\": trainloss,\n",
    "                        \"ValAccuracy\": valacc,\n",
    "                        \"ValLoss\": valloss,\n",
    "                        \"GPUCount\": amount_of_GPUs_to_run,\n",
    "                        \"PreTrain\": (operations_dictionary[run_number_key])[1],\n",
    "                        \"SyncAmount\": (operations_dictionary[run_number_key])[3],\n",
    "                        \"MergeType\": name,\n",
    "                        \"TrainTime\": total_time/amount_of_GPUs_to_run,\n",
    "                        \"SavePathInput\": saved_model_path,\n",
    "                        \"SavePathOutput\": PATH\n",
    "                }\n",
    "\n",
    "            # Adding the new row to the DataFrame\n",
    "            InfoSave.loc[len(InfoSave)] = new_row_data\n",
    "\n",
    "file_path = '../SynchronizationProject/SaveData/DataFrames/InfoSave.csv'\n",
    "\n",
    "InfoSave.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T04:06:06.261748200Z",
     "start_time": "2023-11-19T03:10:39.807733900Z"
    }
   },
   "id": "bb955564ff30a129"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate The Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "684e622953828794"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "file_path = '../SynchronizationProject/SaveData/DataFrames/InfoSave.csv'\n",
    "\n",
    "InfoSave = pd.read_csv(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T04:06:06.276761100Z",
     "start_time": "2023-11-19T04:06:06.264249900Z"
    }
   },
   "id": "558a8f968704739e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "    Run  BatchSize  LearningRate  Epochs  TrainAccuracy  TrainLoss  \\\n0     0         32        0.0001      30      51.664006   1.699703   \n1     1         32        0.0001      30      53.100823   2.106243   \n2     1         32        0.0001      30      53.567481   2.053703   \n3     1         32        0.0001      30      54.255189   2.038396   \n4     1         32        0.0001      30      53.407835   2.136251   \n5     2         32        0.0001      30      87.559867   0.406322   \n6     2         32        0.0001      30      87.191453   0.409149   \n7     2         32        0.0001      30      86.773916   0.444304   \n8     2         32        0.0001      30      86.331819   0.434011   \n9     3         32        0.0001      30      96.315854   0.121388   \n10    3         32        0.0001      30      95.677269   0.143181   \n11    3         32        0.0001      30      96.757952   0.105359   \n12    3         32        0.0001      30      95.615866   0.145272   \n13    4         32        0.0001      30      96.819354   0.101289   \n14    4         32        0.0001      30      98.157927   0.062777   \n15    4         32        0.0001      30      98.600025   0.046820   \n16    4         32        0.0001      30      96.143927   0.123886   \n17    5         32        0.0001      30      36.915142   3.119147   \n18    5         32        0.0001      30      39.272995   2.925477   \n19    5         32        0.0001      30      38.437922   3.065917   \n20    5         32        0.0001      30      40.194032   2.908287   \n21    6         32        0.0001      30      78.349503   0.723268   \n22    6         32        0.0001      30      76.691637   0.780441   \n23    6         32        0.0001      30      77.453027   0.746703   \n24    6         32        0.0001      30      78.386344   0.719206   \n25    7         32        0.0001      30      91.759794   0.264322   \n26    7         32        0.0001      30      93.000123   0.221657   \n27    7         32        0.0001      30      92.840476   0.232415   \n28    7         32        0.0001      30      93.884318   0.199769   \n29    8         32        0.0001      30      97.568464   0.081725   \n30    8         32        0.0001      30      95.996561   0.135764   \n31    8         32        0.0001      30      95.480781   0.136372   \n32    8         32        0.0001      30      97.273732   0.085472   \n33    9         32        0.0001      30      29.645094   3.515307   \n34    9         32        0.0001      30      31.057350   3.359144   \n35    9         32        0.0001      30      30.738057   3.430875   \n36    9         32        0.0001      30      29.534570   3.524286   \n37   10         32        0.0001      30      72.737320   0.916100   \n38   10         32        0.0001      30      71.791723   0.959766   \n39   10         32        0.0001      30      72.626796   0.922173   \n40   10         32        0.0001      30      70.612796   0.984623   \n41   11         32        0.0001      30      88.345818   0.373196   \n42   11         32        0.0001      30      90.851038   0.304804   \n43   11         32        0.0001      30      89.426501   0.336285   \n44   11         32        0.0001      30      91.280855   0.272097   \n45   12         32        0.0001      30      95.308854   0.151857   \n46   12         32        0.0001      30      94.547464   0.178339   \n47   12         32        0.0001      30      94.768513   0.159771   \n48   12         32        0.0001      30      95.824635   0.134130   \n49    0         32        0.0001      30      99.987720   0.001368   \n\n    TrainHistory  ValAccuracy   ValLoss  ValHistory  GPUCount  PreTrain  \\\n0            NaN    19.701369  3.085122         NaN         1      True   \n1            NaN    18.249689  4.704306         NaN         3      True   \n2            NaN    19.411033  4.553074         NaN         3      True   \n3            NaN    17.710494  4.637630         NaN         3      True   \n4            NaN    16.756533  4.647627         NaN         3      True   \n5            NaN    21.775197  4.235407         NaN         3      True   \n6            NaN    20.489423  4.286416         NaN         3      True   \n7            NaN    21.070095  4.208743         NaN         3      True   \n8            NaN    21.899627  4.256384         NaN         3      True   \n9            NaN    19.867275  4.972280         NaN         3      True   \n10           NaN    20.033181  5.017101         NaN         3      True   \n11           NaN    20.945666  4.854669         NaN         3      True   \n12           NaN    20.199088  4.995146         NaN         3      True   \n13           NaN    17.420158  5.510032         NaN         3      True   \n14           NaN    19.162173  5.551418         NaN         3      True   \n15           NaN    18.705931  5.478495         NaN         3      True   \n16           NaN    18.291165  5.526574         NaN         3      True   \n17           NaN    16.175861  4.768898         NaN         5      True   \n18           NaN    15.470759  4.771404         NaN         5      True   \n19           NaN    14.807134  4.892496         NaN         5      True   \n20           NaN    17.212775  4.735627         NaN         5      True   \n21           NaN    21.567814  4.170887         NaN         5      True   \n22           NaN    21.733720  4.087305         NaN         5      True   \n23           NaN    22.107010  4.109139         NaN         5      True   \n24           NaN    22.521775  4.020560         NaN         5      True   \n25           NaN    19.825798  4.948955         NaN         5      True   \n26           NaN    20.240564  4.973072         NaN         5      True   \n27           NaN    20.282041  4.865599         NaN         5      True   \n28           NaN    20.572377  5.011252         NaN         5      True   \n29           NaN    19.079220  5.495300         NaN         5      True   \n30           NaN    18.083783  5.740484         NaN         5      True   \n31           NaN    18.000830  5.708257         NaN         5      True   \n32           NaN    19.037744  5.489053         NaN         5      True   \n33           NaN    13.770220  4.736606         NaN         8      True   \n34           NaN    14.890087  4.577144         NaN         8      True   \n35           NaN    14.350892  4.732373         NaN         8      True   \n36           NaN    14.724181  4.776241         NaN         8      True   \n37           NaN    19.328080  4.140318         NaN         8      True   \n38           NaN    19.991705  4.118856         NaN         8      True   \n39           NaN    20.323517  4.020603         NaN         8      True   \n40           NaN    21.816674  4.036138         NaN         8      True   \n41           NaN    18.913314  5.010839         NaN         8      True   \n42           NaN    18.996267  4.976684         NaN         8      True   \n43           NaN    19.576939  4.962549         NaN         8      True   \n44           NaN    18.913314  5.000330         NaN         8      True   \n45           NaN    16.715056  5.588741         NaN         8      True   \n46           NaN    16.963915  5.673513         NaN         8      True   \n47           NaN    17.627540  5.693550         NaN         8      True   \n48           NaN    18.249689  5.474862         NaN         8      True   \n49           NaN    20.364994  5.352941         NaN         1      True   \n\n    SyncAmount      MergeType    TrainTime  \\\n0            1           NONE   115.654684   \n1            1  MaximumWeight  1424.658157   \n2            1  MinimumWeight  1422.750619   \n3            1   MedianWeight  1419.755907   \n4            1     MeanWeight  1420.320701   \n5            3  MaximumWeight  1419.135626   \n6            3  MinimumWeight  1427.979664   \n7            3   MedianWeight  1419.323161   \n8            3     MeanWeight  1415.948162   \n9            5  MaximumWeight  1415.798911   \n10           5  MinimumWeight  1412.537450   \n11           5   MedianWeight  1413.700198   \n12           5     MeanWeight  1413.029898   \n13          10  MaximumWeight  1410.700898   \n14          10  MinimumWeight  1412.459094   \n15          10   MedianWeight  1415.313916   \n16          10     MeanWeight  1412.853357   \n17           1  MaximumWeight  1062.620167   \n18           1  MinimumWeight  1061.240150   \n19           1   MedianWeight  1060.128267   \n20           1     MeanWeight  1079.978416   \n21           3  MaximumWeight  1066.353251   \n22           3  MinimumWeight  1063.466095   \n23           3   MedianWeight  1062.800848   \n24           3     MeanWeight  1063.042289   \n25           5  MaximumWeight  1063.573231   \n26           5  MinimumWeight  1063.031358   \n27           5   MedianWeight  1063.848073   \n28           5     MeanWeight  1063.060886   \n29          10  MaximumWeight  1063.247362   \n30          10  MinimumWeight  1063.229525   \n31          10   MedianWeight  1065.171318   \n32          10     MeanWeight  1064.032728   \n33           1  MaximumWeight   864.726966   \n34           1  MinimumWeight   864.895276   \n35           1   MedianWeight   864.959193   \n36           1     MeanWeight   867.734026   \n37           3  MaximumWeight   863.361142   \n38           3  MinimumWeight   864.510483   \n39           3   MedianWeight   865.811979   \n40           3     MeanWeight   868.123575   \n41           5  MaximumWeight   870.486011   \n42           5  MinimumWeight   869.489150   \n43           5   MedianWeight   871.397367   \n44           5     MeanWeight   869.272978   \n45          10  MaximumWeight   869.521207   \n46          10  MinimumWeight   871.161117   \n47          10   MedianWeight   873.060223   \n48          10     MeanWeight   871.158229   \n49           1           NONE  3246.804967   \n\n                                       SavePathInput  \\\n0   ../SynchronizationProject/SaveData/PreSave15.pth   \n1   ../SynchronizationProject/SaveData/PreSave15.pth   \n2   ../SynchronizationProject/SaveData/PreSave15.pth   \n3   ../SynchronizationProject/SaveData/PreSave15.pth   \n4   ../SynchronizationProject/SaveData/PreSave15.pth   \n5   ../SynchronizationProject/SaveData/PreSave15.pth   \n6   ../SynchronizationProject/SaveData/PreSave15.pth   \n7   ../SynchronizationProject/SaveData/PreSave15.pth   \n8   ../SynchronizationProject/SaveData/PreSave15.pth   \n9   ../SynchronizationProject/SaveData/PreSave15.pth   \n10  ../SynchronizationProject/SaveData/PreSave15.pth   \n11  ../SynchronizationProject/SaveData/PreSave15.pth   \n12  ../SynchronizationProject/SaveData/PreSave15.pth   \n13  ../SynchronizationProject/SaveData/PreSave15.pth   \n14  ../SynchronizationProject/SaveData/PreSave15.pth   \n15  ../SynchronizationProject/SaveData/PreSave15.pth   \n16  ../SynchronizationProject/SaveData/PreSave15.pth   \n17  ../SynchronizationProject/SaveData/PreSave15.pth   \n18  ../SynchronizationProject/SaveData/PreSave15.pth   \n19  ../SynchronizationProject/SaveData/PreSave15.pth   \n20  ../SynchronizationProject/SaveData/PreSave15.pth   \n21  ../SynchronizationProject/SaveData/PreSave15.pth   \n22  ../SynchronizationProject/SaveData/PreSave15.pth   \n23  ../SynchronizationProject/SaveData/PreSave15.pth   \n24  ../SynchronizationProject/SaveData/PreSave15.pth   \n25  ../SynchronizationProject/SaveData/PreSave15.pth   \n26  ../SynchronizationProject/SaveData/PreSave15.pth   \n27  ../SynchronizationProject/SaveData/PreSave15.pth   \n28  ../SynchronizationProject/SaveData/PreSave15.pth   \n29  ../SynchronizationProject/SaveData/PreSave15.pth   \n30  ../SynchronizationProject/SaveData/PreSave15.pth   \n31  ../SynchronizationProject/SaveData/PreSave15.pth   \n32  ../SynchronizationProject/SaveData/PreSave15.pth   \n33  ../SynchronizationProject/SaveData/PreSave15.pth   \n34  ../SynchronizationProject/SaveData/PreSave15.pth   \n35  ../SynchronizationProject/SaveData/PreSave15.pth   \n36  ../SynchronizationProject/SaveData/PreSave15.pth   \n37  ../SynchronizationProject/SaveData/PreSave15.pth   \n38  ../SynchronizationProject/SaveData/PreSave15.pth   \n39  ../SynchronizationProject/SaveData/PreSave15.pth   \n40  ../SynchronizationProject/SaveData/PreSave15.pth   \n41  ../SynchronizationProject/SaveData/PreSave15.pth   \n42  ../SynchronizationProject/SaveData/PreSave15.pth   \n43  ../SynchronizationProject/SaveData/PreSave15.pth   \n44  ../SynchronizationProject/SaveData/PreSave15.pth   \n45  ../SynchronizationProject/SaveData/PreSave15.pth   \n46  ../SynchronizationProject/SaveData/PreSave15.pth   \n47  ../SynchronizationProject/SaveData/PreSave15.pth   \n48  ../SynchronizationProject/SaveData/PreSave15.pth   \n49  ../SynchronizationProject/SaveData/PreSave15.pth   \n\n                                       SavePathOutput  \n0    ../SynchronizationProject/SaveData/Weights/0.pth  \n1   ../SynchronizationProject/SaveData/Weights/1Ma...  \n2   ../SynchronizationProject/SaveData/Weights/1Mi...  \n3   ../SynchronizationProject/SaveData/Weights/1Me...  \n4   ../SynchronizationProject/SaveData/Weights/1Me...  \n5   ../SynchronizationProject/SaveData/Weights/2Ma...  \n6   ../SynchronizationProject/SaveData/Weights/2Mi...  \n7   ../SynchronizationProject/SaveData/Weights/2Me...  \n8   ../SynchronizationProject/SaveData/Weights/2Me...  \n9   ../SynchronizationProject/SaveData/Weights/3Ma...  \n10  ../SynchronizationProject/SaveData/Weights/3Mi...  \n11  ../SynchronizationProject/SaveData/Weights/3Me...  \n12  ../SynchronizationProject/SaveData/Weights/3Me...  \n13  ../SynchronizationProject/SaveData/Weights/4Ma...  \n14  ../SynchronizationProject/SaveData/Weights/4Mi...  \n15  ../SynchronizationProject/SaveData/Weights/4Me...  \n16  ../SynchronizationProject/SaveData/Weights/4Me...  \n17  ../SynchronizationProject/SaveData/Weights/5Ma...  \n18  ../SynchronizationProject/SaveData/Weights/5Mi...  \n19  ../SynchronizationProject/SaveData/Weights/5Me...  \n20  ../SynchronizationProject/SaveData/Weights/5Me...  \n21  ../SynchronizationProject/SaveData/Weights/6Ma...  \n22  ../SynchronizationProject/SaveData/Weights/6Mi...  \n23  ../SynchronizationProject/SaveData/Weights/6Me...  \n24  ../SynchronizationProject/SaveData/Weights/6Me...  \n25  ../SynchronizationProject/SaveData/Weights/7Ma...  \n26  ../SynchronizationProject/SaveData/Weights/7Mi...  \n27  ../SynchronizationProject/SaveData/Weights/7Me...  \n28  ../SynchronizationProject/SaveData/Weights/7Me...  \n29  ../SynchronizationProject/SaveData/Weights/8Ma...  \n30  ../SynchronizationProject/SaveData/Weights/8Mi...  \n31  ../SynchronizationProject/SaveData/Weights/8Me...  \n32  ../SynchronizationProject/SaveData/Weights/8Me...  \n33  ../SynchronizationProject/SaveData/Weights/9Ma...  \n34  ../SynchronizationProject/SaveData/Weights/9Mi...  \n35  ../SynchronizationProject/SaveData/Weights/9Me...  \n36  ../SynchronizationProject/SaveData/Weights/9Me...  \n37  ../SynchronizationProject/SaveData/Weights/10M...  \n38  ../SynchronizationProject/SaveData/Weights/10M...  \n39  ../SynchronizationProject/SaveData/Weights/10M...  \n40  ../SynchronizationProject/SaveData/Weights/10M...  \n41  ../SynchronizationProject/SaveData/Weights/11M...  \n42  ../SynchronizationProject/SaveData/Weights/11M...  \n43  ../SynchronizationProject/SaveData/Weights/11M...  \n44  ../SynchronizationProject/SaveData/Weights/11M...  \n45  ../SynchronizationProject/SaveData/Weights/12M...  \n46  ../SynchronizationProject/SaveData/Weights/12M...  \n47  ../SynchronizationProject/SaveData/Weights/12M...  \n48  ../SynchronizationProject/SaveData/Weights/12M...  \n49   ../SynchronizationProject/SaveData/Weights/0.pth  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run</th>\n      <th>BatchSize</th>\n      <th>LearningRate</th>\n      <th>Epochs</th>\n      <th>TrainAccuracy</th>\n      <th>TrainLoss</th>\n      <th>TrainHistory</th>\n      <th>ValAccuracy</th>\n      <th>ValLoss</th>\n      <th>ValHistory</th>\n      <th>GPUCount</th>\n      <th>PreTrain</th>\n      <th>SyncAmount</th>\n      <th>MergeType</th>\n      <th>TrainTime</th>\n      <th>SavePathInput</th>\n      <th>SavePathOutput</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>51.664006</td>\n      <td>1.699703</td>\n      <td>NaN</td>\n      <td>19.701369</td>\n      <td>3.085122</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NONE</td>\n      <td>115.654684</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/0.pth</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>53.100823</td>\n      <td>2.106243</td>\n      <td>NaN</td>\n      <td>18.249689</td>\n      <td>4.704306</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MaximumWeight</td>\n      <td>1424.658157</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Ma...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>53.567481</td>\n      <td>2.053703</td>\n      <td>NaN</td>\n      <td>19.411033</td>\n      <td>4.553074</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MinimumWeight</td>\n      <td>1422.750619</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Mi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>54.255189</td>\n      <td>2.038396</td>\n      <td>NaN</td>\n      <td>17.710494</td>\n      <td>4.637630</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MedianWeight</td>\n      <td>1419.755907</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Me...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>53.407835</td>\n      <td>2.136251</td>\n      <td>NaN</td>\n      <td>16.756533</td>\n      <td>4.647627</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MeanWeight</td>\n      <td>1420.320701</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Me...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>87.559867</td>\n      <td>0.406322</td>\n      <td>NaN</td>\n      <td>21.775197</td>\n      <td>4.235407</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MaximumWeight</td>\n      <td>1419.135626</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Ma...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>87.191453</td>\n      <td>0.409149</td>\n      <td>NaN</td>\n      <td>20.489423</td>\n      <td>4.286416</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MinimumWeight</td>\n      <td>1427.979664</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Mi...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>86.773916</td>\n      <td>0.444304</td>\n      <td>NaN</td>\n      <td>21.070095</td>\n      <td>4.208743</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MedianWeight</td>\n      <td>1419.323161</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Me...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>86.331819</td>\n      <td>0.434011</td>\n      <td>NaN</td>\n      <td>21.899627</td>\n      <td>4.256384</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MeanWeight</td>\n      <td>1415.948162</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Me...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.315854</td>\n      <td>0.121388</td>\n      <td>NaN</td>\n      <td>19.867275</td>\n      <td>4.972280</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MaximumWeight</td>\n      <td>1415.798911</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Ma...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.677269</td>\n      <td>0.143181</td>\n      <td>NaN</td>\n      <td>20.033181</td>\n      <td>5.017101</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MinimumWeight</td>\n      <td>1412.537450</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Mi...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.757952</td>\n      <td>0.105359</td>\n      <td>NaN</td>\n      <td>20.945666</td>\n      <td>4.854669</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MedianWeight</td>\n      <td>1413.700198</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Me...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.615866</td>\n      <td>0.145272</td>\n      <td>NaN</td>\n      <td>20.199088</td>\n      <td>4.995146</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MeanWeight</td>\n      <td>1413.029898</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Me...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.819354</td>\n      <td>0.101289</td>\n      <td>NaN</td>\n      <td>17.420158</td>\n      <td>5.510032</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MaximumWeight</td>\n      <td>1410.700898</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Ma...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>98.157927</td>\n      <td>0.062777</td>\n      <td>NaN</td>\n      <td>19.162173</td>\n      <td>5.551418</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MinimumWeight</td>\n      <td>1412.459094</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Mi...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>98.600025</td>\n      <td>0.046820</td>\n      <td>NaN</td>\n      <td>18.705931</td>\n      <td>5.478495</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MedianWeight</td>\n      <td>1415.313916</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Me...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.143927</td>\n      <td>0.123886</td>\n      <td>NaN</td>\n      <td>18.291165</td>\n      <td>5.526574</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MeanWeight</td>\n      <td>1412.853357</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Me...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>36.915142</td>\n      <td>3.119147</td>\n      <td>NaN</td>\n      <td>16.175861</td>\n      <td>4.768898</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MaximumWeight</td>\n      <td>1062.620167</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Ma...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>39.272995</td>\n      <td>2.925477</td>\n      <td>NaN</td>\n      <td>15.470759</td>\n      <td>4.771404</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MinimumWeight</td>\n      <td>1061.240150</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Mi...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>38.437922</td>\n      <td>3.065917</td>\n      <td>NaN</td>\n      <td>14.807134</td>\n      <td>4.892496</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MedianWeight</td>\n      <td>1060.128267</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Me...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>40.194032</td>\n      <td>2.908287</td>\n      <td>NaN</td>\n      <td>17.212775</td>\n      <td>4.735627</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MeanWeight</td>\n      <td>1079.978416</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Me...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>78.349503</td>\n      <td>0.723268</td>\n      <td>NaN</td>\n      <td>21.567814</td>\n      <td>4.170887</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MaximumWeight</td>\n      <td>1066.353251</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Ma...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>76.691637</td>\n      <td>0.780441</td>\n      <td>NaN</td>\n      <td>21.733720</td>\n      <td>4.087305</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MinimumWeight</td>\n      <td>1063.466095</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Mi...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>77.453027</td>\n      <td>0.746703</td>\n      <td>NaN</td>\n      <td>22.107010</td>\n      <td>4.109139</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MedianWeight</td>\n      <td>1062.800848</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Me...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>78.386344</td>\n      <td>0.719206</td>\n      <td>NaN</td>\n      <td>22.521775</td>\n      <td>4.020560</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MeanWeight</td>\n      <td>1063.042289</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Me...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>91.759794</td>\n      <td>0.264322</td>\n      <td>NaN</td>\n      <td>19.825798</td>\n      <td>4.948955</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MaximumWeight</td>\n      <td>1063.573231</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Ma...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>93.000123</td>\n      <td>0.221657</td>\n      <td>NaN</td>\n      <td>20.240564</td>\n      <td>4.973072</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MinimumWeight</td>\n      <td>1063.031358</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Mi...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>92.840476</td>\n      <td>0.232415</td>\n      <td>NaN</td>\n      <td>20.282041</td>\n      <td>4.865599</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MedianWeight</td>\n      <td>1063.848073</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Me...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>93.884318</td>\n      <td>0.199769</td>\n      <td>NaN</td>\n      <td>20.572377</td>\n      <td>5.011252</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MeanWeight</td>\n      <td>1063.060886</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Me...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>97.568464</td>\n      <td>0.081725</td>\n      <td>NaN</td>\n      <td>19.079220</td>\n      <td>5.495300</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MaximumWeight</td>\n      <td>1063.247362</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Ma...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.996561</td>\n      <td>0.135764</td>\n      <td>NaN</td>\n      <td>18.083783</td>\n      <td>5.740484</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MinimumWeight</td>\n      <td>1063.229525</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Mi...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.480781</td>\n      <td>0.136372</td>\n      <td>NaN</td>\n      <td>18.000830</td>\n      <td>5.708257</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MedianWeight</td>\n      <td>1065.171318</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Me...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>97.273732</td>\n      <td>0.085472</td>\n      <td>NaN</td>\n      <td>19.037744</td>\n      <td>5.489053</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MeanWeight</td>\n      <td>1064.032728</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Me...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>29.645094</td>\n      <td>3.515307</td>\n      <td>NaN</td>\n      <td>13.770220</td>\n      <td>4.736606</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MaximumWeight</td>\n      <td>864.726966</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Ma...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>31.057350</td>\n      <td>3.359144</td>\n      <td>NaN</td>\n      <td>14.890087</td>\n      <td>4.577144</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MinimumWeight</td>\n      <td>864.895276</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Mi...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>30.738057</td>\n      <td>3.430875</td>\n      <td>NaN</td>\n      <td>14.350892</td>\n      <td>4.732373</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MedianWeight</td>\n      <td>864.959193</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Me...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>29.534570</td>\n      <td>3.524286</td>\n      <td>NaN</td>\n      <td>14.724181</td>\n      <td>4.776241</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MeanWeight</td>\n      <td>867.734026</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Me...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>72.737320</td>\n      <td>0.916100</td>\n      <td>NaN</td>\n      <td>19.328080</td>\n      <td>4.140318</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MaximumWeight</td>\n      <td>863.361142</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>71.791723</td>\n      <td>0.959766</td>\n      <td>NaN</td>\n      <td>19.991705</td>\n      <td>4.118856</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MinimumWeight</td>\n      <td>864.510483</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>72.626796</td>\n      <td>0.922173</td>\n      <td>NaN</td>\n      <td>20.323517</td>\n      <td>4.020603</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MedianWeight</td>\n      <td>865.811979</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>70.612796</td>\n      <td>0.984623</td>\n      <td>NaN</td>\n      <td>21.816674</td>\n      <td>4.036138</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MeanWeight</td>\n      <td>868.123575</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>88.345818</td>\n      <td>0.373196</td>\n      <td>NaN</td>\n      <td>18.913314</td>\n      <td>5.010839</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MaximumWeight</td>\n      <td>870.486011</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>90.851038</td>\n      <td>0.304804</td>\n      <td>NaN</td>\n      <td>18.996267</td>\n      <td>4.976684</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MinimumWeight</td>\n      <td>869.489150</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>89.426501</td>\n      <td>0.336285</td>\n      <td>NaN</td>\n      <td>19.576939</td>\n      <td>4.962549</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MedianWeight</td>\n      <td>871.397367</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>91.280855</td>\n      <td>0.272097</td>\n      <td>NaN</td>\n      <td>18.913314</td>\n      <td>5.000330</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MeanWeight</td>\n      <td>869.272978</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.308854</td>\n      <td>0.151857</td>\n      <td>NaN</td>\n      <td>16.715056</td>\n      <td>5.588741</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MaximumWeight</td>\n      <td>869.521207</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>94.547464</td>\n      <td>0.178339</td>\n      <td>NaN</td>\n      <td>16.963915</td>\n      <td>5.673513</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MinimumWeight</td>\n      <td>871.161117</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>94.768513</td>\n      <td>0.159771</td>\n      <td>NaN</td>\n      <td>17.627540</td>\n      <td>5.693550</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MedianWeight</td>\n      <td>873.060223</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.824635</td>\n      <td>0.134130</td>\n      <td>NaN</td>\n      <td>18.249689</td>\n      <td>5.474862</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MeanWeight</td>\n      <td>871.158229</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>99.987720</td>\n      <td>0.001368</td>\n      <td>NaN</td>\n      <td>20.364994</td>\n      <td>5.352941</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NONE</td>\n      <td>3246.804967</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/0.pth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InfoSave"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:48:30.122749200Z",
     "start_time": "2023-11-19T06:48:30.089112Z"
    }
   },
   "id": "fc156538971f59c6"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "    Run  BatchSize  LearningRate  Epochs  TrainAccuracy  TrainLoss  \\\n0     0         32        0.0001      30      51.664006   1.699703   \n1     1         32        0.0001      30      53.100823   2.106243   \n2     1         32        0.0001      30      53.567481   2.053703   \n3     1         32        0.0001      30      54.255189   2.038396   \n4     1         32        0.0001      30      53.407835   2.136251   \n5     2         32        0.0001      30      87.559867   0.406322   \n6     2         32        0.0001      30      87.191453   0.409149   \n7     2         32        0.0001      30      86.773916   0.444304   \n8     2         32        0.0001      30      86.331819   0.434011   \n9     3         32        0.0001      30      96.315854   0.121388   \n10    3         32        0.0001      30      95.677269   0.143181   \n11    3         32        0.0001      30      96.757952   0.105359   \n12    3         32        0.0001      30      95.615866   0.145272   \n13    4         32        0.0001      30      96.819354   0.101289   \n14    4         32        0.0001      30      98.157927   0.062777   \n15    4         32        0.0001      30      98.600025   0.046820   \n16    4         32        0.0001      30      96.143927   0.123886   \n17    5         32        0.0001      30      36.915142   3.119147   \n18    5         32        0.0001      30      39.272995   2.925477   \n19    5         32        0.0001      30      38.437922   3.065917   \n20    5         32        0.0001      30      40.194032   2.908287   \n21    6         32        0.0001      30      78.349503   0.723268   \n22    6         32        0.0001      30      76.691637   0.780441   \n23    6         32        0.0001      30      77.453027   0.746703   \n24    6         32        0.0001      30      78.386344   0.719206   \n25    7         32        0.0001      30      91.759794   0.264322   \n26    7         32        0.0001      30      93.000123   0.221657   \n27    7         32        0.0001      30      92.840476   0.232415   \n28    7         32        0.0001      30      93.884318   0.199769   \n29    8         32        0.0001      30      97.568464   0.081725   \n30    8         32        0.0001      30      95.996561   0.135764   \n31    8         32        0.0001      30      95.480781   0.136372   \n32    8         32        0.0001      30      97.273732   0.085472   \n33    9         32        0.0001      30      29.645094   3.515307   \n34    9         32        0.0001      30      31.057350   3.359144   \n35    9         32        0.0001      30      30.738057   3.430875   \n36    9         32        0.0001      30      29.534570   3.524286   \n37   10         32        0.0001      30      72.737320   0.916100   \n38   10         32        0.0001      30      71.791723   0.959766   \n39   10         32        0.0001      30      72.626796   0.922173   \n40   10         32        0.0001      30      70.612796   0.984623   \n41   11         32        0.0001      30      88.345818   0.373196   \n42   11         32        0.0001      30      90.851038   0.304804   \n43   11         32        0.0001      30      89.426501   0.336285   \n44   11         32        0.0001      30      91.280855   0.272097   \n45   12         32        0.0001      30      95.308854   0.151857   \n46   12         32        0.0001      30      94.547464   0.178339   \n47   12         32        0.0001      30      94.768513   0.159771   \n48   12         32        0.0001      30      95.824635   0.134130   \n49    0         32        0.0001      30      99.987720   0.001368   \n\n    TrainHistory  ValAccuracy   ValLoss  ValHistory  GPUCount  PreTrain  \\\n0            NaN    19.701369  3.085122         NaN         1      True   \n1            NaN    18.249689  4.704306         NaN         3      True   \n2            NaN    19.411033  4.553074         NaN         3      True   \n3            NaN    17.710494  4.637630         NaN         3      True   \n4            NaN    16.756533  4.647627         NaN         3      True   \n5            NaN    21.775197  4.235407         NaN         3      True   \n6            NaN    20.489423  4.286416         NaN         3      True   \n7            NaN    21.070095  4.208743         NaN         3      True   \n8            NaN    21.899627  4.256384         NaN         3      True   \n9            NaN    19.867275  4.972280         NaN         3      True   \n10           NaN    20.033181  5.017101         NaN         3      True   \n11           NaN    20.945666  4.854669         NaN         3      True   \n12           NaN    20.199088  4.995146         NaN         3      True   \n13           NaN    17.420158  5.510032         NaN         3      True   \n14           NaN    19.162173  5.551418         NaN         3      True   \n15           NaN    18.705931  5.478495         NaN         3      True   \n16           NaN    18.291165  5.526574         NaN         3      True   \n17           NaN    16.175861  4.768898         NaN         5      True   \n18           NaN    15.470759  4.771404         NaN         5      True   \n19           NaN    14.807134  4.892496         NaN         5      True   \n20           NaN    17.212775  4.735627         NaN         5      True   \n21           NaN    21.567814  4.170887         NaN         5      True   \n22           NaN    21.733720  4.087305         NaN         5      True   \n23           NaN    22.107010  4.109139         NaN         5      True   \n24           NaN    22.521775  4.020560         NaN         5      True   \n25           NaN    19.825798  4.948955         NaN         5      True   \n26           NaN    20.240564  4.973072         NaN         5      True   \n27           NaN    20.282041  4.865599         NaN         5      True   \n28           NaN    20.572377  5.011252         NaN         5      True   \n29           NaN    19.079220  5.495300         NaN         5      True   \n30           NaN    18.083783  5.740484         NaN         5      True   \n31           NaN    18.000830  5.708257         NaN         5      True   \n32           NaN    19.037744  5.489053         NaN         5      True   \n33           NaN    13.770220  4.736606         NaN         8      True   \n34           NaN    14.890087  4.577144         NaN         8      True   \n35           NaN    14.350892  4.732373         NaN         8      True   \n36           NaN    14.724181  4.776241         NaN         8      True   \n37           NaN    19.328080  4.140318         NaN         8      True   \n38           NaN    19.991705  4.118856         NaN         8      True   \n39           NaN    20.323517  4.020603         NaN         8      True   \n40           NaN    21.816674  4.036138         NaN         8      True   \n41           NaN    18.913314  5.010839         NaN         8      True   \n42           NaN    18.996267  4.976684         NaN         8      True   \n43           NaN    19.576939  4.962549         NaN         8      True   \n44           NaN    18.913314  5.000330         NaN         8      True   \n45           NaN    16.715056  5.588741         NaN         8      True   \n46           NaN    16.963915  5.673513         NaN         8      True   \n47           NaN    17.627540  5.693550         NaN         8      True   \n48           NaN    18.249689  5.474862         NaN         8      True   \n49           NaN    20.364994  5.352941         NaN         1      True   \n\n    SyncAmount      MergeType    TrainTime  \\\n0            1           NONE   115.654684   \n1            1  MaximumWeight  1424.658157   \n2            1  MinimumWeight  1422.750619   \n3            1   MedianWeight  1419.755907   \n4            1     MeanWeight  1420.320701   \n5            3  MaximumWeight  1419.135626   \n6            3  MinimumWeight  1427.979664   \n7            3   MedianWeight  1419.323161   \n8            3     MeanWeight  1415.948162   \n9            5  MaximumWeight  1415.798911   \n10           5  MinimumWeight  1412.537450   \n11           5   MedianWeight  1413.700198   \n12           5     MeanWeight  1413.029898   \n13          10  MaximumWeight  1410.700898   \n14          10  MinimumWeight  1412.459094   \n15          10   MedianWeight  1415.313916   \n16          10     MeanWeight  1412.853357   \n17           1  MaximumWeight  1062.620167   \n18           1  MinimumWeight  1061.240150   \n19           1   MedianWeight  1060.128267   \n20           1     MeanWeight  1079.978416   \n21           3  MaximumWeight  1066.353251   \n22           3  MinimumWeight  1063.466095   \n23           3   MedianWeight  1062.800848   \n24           3     MeanWeight  1063.042289   \n25           5  MaximumWeight  1063.573231   \n26           5  MinimumWeight  1063.031358   \n27           5   MedianWeight  1063.848073   \n28           5     MeanWeight  1063.060886   \n29          10  MaximumWeight  1063.247362   \n30          10  MinimumWeight  1063.229525   \n31          10   MedianWeight  1065.171318   \n32          10     MeanWeight  1064.032728   \n33           1  MaximumWeight   864.726966   \n34           1  MinimumWeight   864.895276   \n35           1   MedianWeight   864.959193   \n36           1     MeanWeight   867.734026   \n37           3  MaximumWeight   863.361142   \n38           3  MinimumWeight   864.510483   \n39           3   MedianWeight   865.811979   \n40           3     MeanWeight   868.123575   \n41           5  MaximumWeight   870.486011   \n42           5  MinimumWeight   869.489150   \n43           5   MedianWeight   871.397367   \n44           5     MeanWeight   869.272978   \n45          10  MaximumWeight   869.521207   \n46          10  MinimumWeight   871.161117   \n47          10   MedianWeight   873.060223   \n48          10     MeanWeight   871.158229   \n49           1           NONE  3246.804967   \n\n                                       SavePathInput  \\\n0   ../SynchronizationProject/SaveData/PreSave15.pth   \n1   ../SynchronizationProject/SaveData/PreSave15.pth   \n2   ../SynchronizationProject/SaveData/PreSave15.pth   \n3   ../SynchronizationProject/SaveData/PreSave15.pth   \n4   ../SynchronizationProject/SaveData/PreSave15.pth   \n5   ../SynchronizationProject/SaveData/PreSave15.pth   \n6   ../SynchronizationProject/SaveData/PreSave15.pth   \n7   ../SynchronizationProject/SaveData/PreSave15.pth   \n8   ../SynchronizationProject/SaveData/PreSave15.pth   \n9   ../SynchronizationProject/SaveData/PreSave15.pth   \n10  ../SynchronizationProject/SaveData/PreSave15.pth   \n11  ../SynchronizationProject/SaveData/PreSave15.pth   \n12  ../SynchronizationProject/SaveData/PreSave15.pth   \n13  ../SynchronizationProject/SaveData/PreSave15.pth   \n14  ../SynchronizationProject/SaveData/PreSave15.pth   \n15  ../SynchronizationProject/SaveData/PreSave15.pth   \n16  ../SynchronizationProject/SaveData/PreSave15.pth   \n17  ../SynchronizationProject/SaveData/PreSave15.pth   \n18  ../SynchronizationProject/SaveData/PreSave15.pth   \n19  ../SynchronizationProject/SaveData/PreSave15.pth   \n20  ../SynchronizationProject/SaveData/PreSave15.pth   \n21  ../SynchronizationProject/SaveData/PreSave15.pth   \n22  ../SynchronizationProject/SaveData/PreSave15.pth   \n23  ../SynchronizationProject/SaveData/PreSave15.pth   \n24  ../SynchronizationProject/SaveData/PreSave15.pth   \n25  ../SynchronizationProject/SaveData/PreSave15.pth   \n26  ../SynchronizationProject/SaveData/PreSave15.pth   \n27  ../SynchronizationProject/SaveData/PreSave15.pth   \n28  ../SynchronizationProject/SaveData/PreSave15.pth   \n29  ../SynchronizationProject/SaveData/PreSave15.pth   \n30  ../SynchronizationProject/SaveData/PreSave15.pth   \n31  ../SynchronizationProject/SaveData/PreSave15.pth   \n32  ../SynchronizationProject/SaveData/PreSave15.pth   \n33  ../SynchronizationProject/SaveData/PreSave15.pth   \n34  ../SynchronizationProject/SaveData/PreSave15.pth   \n35  ../SynchronizationProject/SaveData/PreSave15.pth   \n36  ../SynchronizationProject/SaveData/PreSave15.pth   \n37  ../SynchronizationProject/SaveData/PreSave15.pth   \n38  ../SynchronizationProject/SaveData/PreSave15.pth   \n39  ../SynchronizationProject/SaveData/PreSave15.pth   \n40  ../SynchronizationProject/SaveData/PreSave15.pth   \n41  ../SynchronizationProject/SaveData/PreSave15.pth   \n42  ../SynchronizationProject/SaveData/PreSave15.pth   \n43  ../SynchronizationProject/SaveData/PreSave15.pth   \n44  ../SynchronizationProject/SaveData/PreSave15.pth   \n45  ../SynchronizationProject/SaveData/PreSave15.pth   \n46  ../SynchronizationProject/SaveData/PreSave15.pth   \n47  ../SynchronizationProject/SaveData/PreSave15.pth   \n48  ../SynchronizationProject/SaveData/PreSave15.pth   \n49  ../SynchronizationProject/SaveData/PreSave15.pth   \n\n                                       SavePathOutput  \n0    ../SynchronizationProject/SaveData/Weights/0.pth  \n1   ../SynchronizationProject/SaveData/Weights/1Ma...  \n2   ../SynchronizationProject/SaveData/Weights/1Mi...  \n3   ../SynchronizationProject/SaveData/Weights/1Me...  \n4   ../SynchronizationProject/SaveData/Weights/1Me...  \n5   ../SynchronizationProject/SaveData/Weights/2Ma...  \n6   ../SynchronizationProject/SaveData/Weights/2Mi...  \n7   ../SynchronizationProject/SaveData/Weights/2Me...  \n8   ../SynchronizationProject/SaveData/Weights/2Me...  \n9   ../SynchronizationProject/SaveData/Weights/3Ma...  \n10  ../SynchronizationProject/SaveData/Weights/3Mi...  \n11  ../SynchronizationProject/SaveData/Weights/3Me...  \n12  ../SynchronizationProject/SaveData/Weights/3Me...  \n13  ../SynchronizationProject/SaveData/Weights/4Ma...  \n14  ../SynchronizationProject/SaveData/Weights/4Mi...  \n15  ../SynchronizationProject/SaveData/Weights/4Me...  \n16  ../SynchronizationProject/SaveData/Weights/4Me...  \n17  ../SynchronizationProject/SaveData/Weights/5Ma...  \n18  ../SynchronizationProject/SaveData/Weights/5Mi...  \n19  ../SynchronizationProject/SaveData/Weights/5Me...  \n20  ../SynchronizationProject/SaveData/Weights/5Me...  \n21  ../SynchronizationProject/SaveData/Weights/6Ma...  \n22  ../SynchronizationProject/SaveData/Weights/6Mi...  \n23  ../SynchronizationProject/SaveData/Weights/6Me...  \n24  ../SynchronizationProject/SaveData/Weights/6Me...  \n25  ../SynchronizationProject/SaveData/Weights/7Ma...  \n26  ../SynchronizationProject/SaveData/Weights/7Mi...  \n27  ../SynchronizationProject/SaveData/Weights/7Me...  \n28  ../SynchronizationProject/SaveData/Weights/7Me...  \n29  ../SynchronizationProject/SaveData/Weights/8Ma...  \n30  ../SynchronizationProject/SaveData/Weights/8Mi...  \n31  ../SynchronizationProject/SaveData/Weights/8Me...  \n32  ../SynchronizationProject/SaveData/Weights/8Me...  \n33  ../SynchronizationProject/SaveData/Weights/9Ma...  \n34  ../SynchronizationProject/SaveData/Weights/9Mi...  \n35  ../SynchronizationProject/SaveData/Weights/9Me...  \n36  ../SynchronizationProject/SaveData/Weights/9Me...  \n37  ../SynchronizationProject/SaveData/Weights/10M...  \n38  ../SynchronizationProject/SaveData/Weights/10M...  \n39  ../SynchronizationProject/SaveData/Weights/10M...  \n40  ../SynchronizationProject/SaveData/Weights/10M...  \n41  ../SynchronizationProject/SaveData/Weights/11M...  \n42  ../SynchronizationProject/SaveData/Weights/11M...  \n43  ../SynchronizationProject/SaveData/Weights/11M...  \n44  ../SynchronizationProject/SaveData/Weights/11M...  \n45  ../SynchronizationProject/SaveData/Weights/12M...  \n46  ../SynchronizationProject/SaveData/Weights/12M...  \n47  ../SynchronizationProject/SaveData/Weights/12M...  \n48  ../SynchronizationProject/SaveData/Weights/12M...  \n49   ../SynchronizationProject/SaveData/Weights/0.pth  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run</th>\n      <th>BatchSize</th>\n      <th>LearningRate</th>\n      <th>Epochs</th>\n      <th>TrainAccuracy</th>\n      <th>TrainLoss</th>\n      <th>TrainHistory</th>\n      <th>ValAccuracy</th>\n      <th>ValLoss</th>\n      <th>ValHistory</th>\n      <th>GPUCount</th>\n      <th>PreTrain</th>\n      <th>SyncAmount</th>\n      <th>MergeType</th>\n      <th>TrainTime</th>\n      <th>SavePathInput</th>\n      <th>SavePathOutput</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>51.664006</td>\n      <td>1.699703</td>\n      <td>NaN</td>\n      <td>19.701369</td>\n      <td>3.085122</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NONE</td>\n      <td>115.654684</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/0.pth</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>53.100823</td>\n      <td>2.106243</td>\n      <td>NaN</td>\n      <td>18.249689</td>\n      <td>4.704306</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MaximumWeight</td>\n      <td>1424.658157</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Ma...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>53.567481</td>\n      <td>2.053703</td>\n      <td>NaN</td>\n      <td>19.411033</td>\n      <td>4.553074</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MinimumWeight</td>\n      <td>1422.750619</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Mi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>54.255189</td>\n      <td>2.038396</td>\n      <td>NaN</td>\n      <td>17.710494</td>\n      <td>4.637630</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MedianWeight</td>\n      <td>1419.755907</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Me...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>53.407835</td>\n      <td>2.136251</td>\n      <td>NaN</td>\n      <td>16.756533</td>\n      <td>4.647627</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MeanWeight</td>\n      <td>1420.320701</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/1Me...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>87.559867</td>\n      <td>0.406322</td>\n      <td>NaN</td>\n      <td>21.775197</td>\n      <td>4.235407</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MaximumWeight</td>\n      <td>1419.135626</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Ma...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>87.191453</td>\n      <td>0.409149</td>\n      <td>NaN</td>\n      <td>20.489423</td>\n      <td>4.286416</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MinimumWeight</td>\n      <td>1427.979664</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Mi...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>86.773916</td>\n      <td>0.444304</td>\n      <td>NaN</td>\n      <td>21.070095</td>\n      <td>4.208743</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MedianWeight</td>\n      <td>1419.323161</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Me...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>86.331819</td>\n      <td>0.434011</td>\n      <td>NaN</td>\n      <td>21.899627</td>\n      <td>4.256384</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MeanWeight</td>\n      <td>1415.948162</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/2Me...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.315854</td>\n      <td>0.121388</td>\n      <td>NaN</td>\n      <td>19.867275</td>\n      <td>4.972280</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MaximumWeight</td>\n      <td>1415.798911</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Ma...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.677269</td>\n      <td>0.143181</td>\n      <td>NaN</td>\n      <td>20.033181</td>\n      <td>5.017101</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MinimumWeight</td>\n      <td>1412.537450</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Mi...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.757952</td>\n      <td>0.105359</td>\n      <td>NaN</td>\n      <td>20.945666</td>\n      <td>4.854669</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MedianWeight</td>\n      <td>1413.700198</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Me...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.615866</td>\n      <td>0.145272</td>\n      <td>NaN</td>\n      <td>20.199088</td>\n      <td>4.995146</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MeanWeight</td>\n      <td>1413.029898</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/3Me...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.819354</td>\n      <td>0.101289</td>\n      <td>NaN</td>\n      <td>17.420158</td>\n      <td>5.510032</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MaximumWeight</td>\n      <td>1410.700898</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Ma...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>98.157927</td>\n      <td>0.062777</td>\n      <td>NaN</td>\n      <td>19.162173</td>\n      <td>5.551418</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MinimumWeight</td>\n      <td>1412.459094</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Mi...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>98.600025</td>\n      <td>0.046820</td>\n      <td>NaN</td>\n      <td>18.705931</td>\n      <td>5.478495</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MedianWeight</td>\n      <td>1415.313916</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Me...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>96.143927</td>\n      <td>0.123886</td>\n      <td>NaN</td>\n      <td>18.291165</td>\n      <td>5.526574</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MeanWeight</td>\n      <td>1412.853357</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/4Me...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>36.915142</td>\n      <td>3.119147</td>\n      <td>NaN</td>\n      <td>16.175861</td>\n      <td>4.768898</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MaximumWeight</td>\n      <td>1062.620167</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Ma...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>39.272995</td>\n      <td>2.925477</td>\n      <td>NaN</td>\n      <td>15.470759</td>\n      <td>4.771404</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MinimumWeight</td>\n      <td>1061.240150</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Mi...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>38.437922</td>\n      <td>3.065917</td>\n      <td>NaN</td>\n      <td>14.807134</td>\n      <td>4.892496</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MedianWeight</td>\n      <td>1060.128267</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Me...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>40.194032</td>\n      <td>2.908287</td>\n      <td>NaN</td>\n      <td>17.212775</td>\n      <td>4.735627</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MeanWeight</td>\n      <td>1079.978416</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/5Me...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>78.349503</td>\n      <td>0.723268</td>\n      <td>NaN</td>\n      <td>21.567814</td>\n      <td>4.170887</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MaximumWeight</td>\n      <td>1066.353251</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Ma...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>76.691637</td>\n      <td>0.780441</td>\n      <td>NaN</td>\n      <td>21.733720</td>\n      <td>4.087305</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MinimumWeight</td>\n      <td>1063.466095</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Mi...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>77.453027</td>\n      <td>0.746703</td>\n      <td>NaN</td>\n      <td>22.107010</td>\n      <td>4.109139</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MedianWeight</td>\n      <td>1062.800848</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Me...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>6</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>78.386344</td>\n      <td>0.719206</td>\n      <td>NaN</td>\n      <td>22.521775</td>\n      <td>4.020560</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MeanWeight</td>\n      <td>1063.042289</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/6Me...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>91.759794</td>\n      <td>0.264322</td>\n      <td>NaN</td>\n      <td>19.825798</td>\n      <td>4.948955</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MaximumWeight</td>\n      <td>1063.573231</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Ma...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>93.000123</td>\n      <td>0.221657</td>\n      <td>NaN</td>\n      <td>20.240564</td>\n      <td>4.973072</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MinimumWeight</td>\n      <td>1063.031358</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Mi...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>92.840476</td>\n      <td>0.232415</td>\n      <td>NaN</td>\n      <td>20.282041</td>\n      <td>4.865599</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MedianWeight</td>\n      <td>1063.848073</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Me...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>7</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>93.884318</td>\n      <td>0.199769</td>\n      <td>NaN</td>\n      <td>20.572377</td>\n      <td>5.011252</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MeanWeight</td>\n      <td>1063.060886</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/7Me...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>97.568464</td>\n      <td>0.081725</td>\n      <td>NaN</td>\n      <td>19.079220</td>\n      <td>5.495300</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MaximumWeight</td>\n      <td>1063.247362</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Ma...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.996561</td>\n      <td>0.135764</td>\n      <td>NaN</td>\n      <td>18.083783</td>\n      <td>5.740484</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MinimumWeight</td>\n      <td>1063.229525</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Mi...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.480781</td>\n      <td>0.136372</td>\n      <td>NaN</td>\n      <td>18.000830</td>\n      <td>5.708257</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MedianWeight</td>\n      <td>1065.171318</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Me...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>8</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>97.273732</td>\n      <td>0.085472</td>\n      <td>NaN</td>\n      <td>19.037744</td>\n      <td>5.489053</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MeanWeight</td>\n      <td>1064.032728</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/8Me...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>29.645094</td>\n      <td>3.515307</td>\n      <td>NaN</td>\n      <td>13.770220</td>\n      <td>4.736606</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MaximumWeight</td>\n      <td>864.726966</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Ma...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>31.057350</td>\n      <td>3.359144</td>\n      <td>NaN</td>\n      <td>14.890087</td>\n      <td>4.577144</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MinimumWeight</td>\n      <td>864.895276</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Mi...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>30.738057</td>\n      <td>3.430875</td>\n      <td>NaN</td>\n      <td>14.350892</td>\n      <td>4.732373</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MedianWeight</td>\n      <td>864.959193</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Me...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>9</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>29.534570</td>\n      <td>3.524286</td>\n      <td>NaN</td>\n      <td>14.724181</td>\n      <td>4.776241</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1</td>\n      <td>MeanWeight</td>\n      <td>867.734026</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/9Me...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>72.737320</td>\n      <td>0.916100</td>\n      <td>NaN</td>\n      <td>19.328080</td>\n      <td>4.140318</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MaximumWeight</td>\n      <td>863.361142</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>71.791723</td>\n      <td>0.959766</td>\n      <td>NaN</td>\n      <td>19.991705</td>\n      <td>4.118856</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MinimumWeight</td>\n      <td>864.510483</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>72.626796</td>\n      <td>0.922173</td>\n      <td>NaN</td>\n      <td>20.323517</td>\n      <td>4.020603</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MedianWeight</td>\n      <td>865.811979</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>10</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>70.612796</td>\n      <td>0.984623</td>\n      <td>NaN</td>\n      <td>21.816674</td>\n      <td>4.036138</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>3</td>\n      <td>MeanWeight</td>\n      <td>868.123575</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/10M...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>88.345818</td>\n      <td>0.373196</td>\n      <td>NaN</td>\n      <td>18.913314</td>\n      <td>5.010839</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MaximumWeight</td>\n      <td>870.486011</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>90.851038</td>\n      <td>0.304804</td>\n      <td>NaN</td>\n      <td>18.996267</td>\n      <td>4.976684</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MinimumWeight</td>\n      <td>869.489150</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>89.426501</td>\n      <td>0.336285</td>\n      <td>NaN</td>\n      <td>19.576939</td>\n      <td>4.962549</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MedianWeight</td>\n      <td>871.397367</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>11</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>91.280855</td>\n      <td>0.272097</td>\n      <td>NaN</td>\n      <td>18.913314</td>\n      <td>5.000330</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>5</td>\n      <td>MeanWeight</td>\n      <td>869.272978</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/11M...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.308854</td>\n      <td>0.151857</td>\n      <td>NaN</td>\n      <td>16.715056</td>\n      <td>5.588741</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MaximumWeight</td>\n      <td>869.521207</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>94.547464</td>\n      <td>0.178339</td>\n      <td>NaN</td>\n      <td>16.963915</td>\n      <td>5.673513</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MinimumWeight</td>\n      <td>871.161117</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>94.768513</td>\n      <td>0.159771</td>\n      <td>NaN</td>\n      <td>17.627540</td>\n      <td>5.693550</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MedianWeight</td>\n      <td>873.060223</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>12</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>95.824635</td>\n      <td>0.134130</td>\n      <td>NaN</td>\n      <td>18.249689</td>\n      <td>5.474862</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>True</td>\n      <td>10</td>\n      <td>MeanWeight</td>\n      <td>871.158229</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/12M...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0</td>\n      <td>32</td>\n      <td>0.0001</td>\n      <td>30</td>\n      <td>99.987720</td>\n      <td>0.001368</td>\n      <td>NaN</td>\n      <td>20.364994</td>\n      <td>5.352941</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NONE</td>\n      <td>3246.804967</td>\n      <td>../SynchronizationProject/SaveData/PreSave15.pth</td>\n      <td>../SynchronizationProject/SaveData/Weights/0.pth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.option_context('display.max_rows', None, 'display.max_columns', None)  # more options can be specified also\n",
    "InfoSave"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T06:48:41.789230500Z",
     "start_time": "2023-11-19T06:48:41.748087700Z"
    }
   },
   "id": "14141d9dfb624fae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36f3609b27e3d3e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
